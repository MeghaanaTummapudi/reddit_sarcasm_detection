{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\prasr\\anaconda3\\envs\\nlp_sarcasm\\lib\\site-packages (from fasttext) (2.8.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\prasr\\anaconda3\\envs\\nlp_sarcasm\\lib\\site-packages (from fasttext) (58.0.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\prasr\\anaconda3\\envs\\nlp_sarcasm\\lib\\site-packages (from fasttext) (1.21.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'done'\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-win_amd64.whl size=240971 sha256=8bf95b1a7c8d551f7bd4f8dccfab3c86cc0558337887fd86da0e4de55bae57f6\n",
      "  Stored in directory: c:\\users\\prasr\\appdata\\local\\pip\\cache\\wheels\\64\\57\\bc\\1741406019061d5664914b070bd3e71f6244648732bc96109e\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.9.2\n"
     ]
    }
   ],
   "source": [
    "! pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,nltk,swifter\n",
    "import csv\n",
    "import fasttext\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from zeugma.embeddings import EmbeddingTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>-4</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>-8</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  score  \\\n",
       "0      0                                         NC and NH.  Trumpbart      2   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906     -4   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth      3   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha     -8   \n",
       "4      0                    I could use one of those tools.  cush2push      6   \n",
       "\n",
       "           created_utc                                     parent_comment  \n",
       "0  2016-10-16 23:55:23  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  2016-11-01 00:24:10  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2  2016-09-22 21:45:37                            They're favored to win.  \n",
       "3  2016-10-18 21:03:47                         deadass don't kill my buzz  \n",
       "4  2016-12-30 17:00:13  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\prasr\\Documents\\Northeastern\\IDMP\\Project\\reddit_sarcasm_detection\\data\\interim\\parent_cleaned_sarcasm_with_sentiment.csv')\n",
    "df = df.fillna('')\n",
    "df = df[['label','comment','author','score','created_utc','parent_comment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['label','comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply: 100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "C:\\Users\\prasr\\AppData\\Local\\Temp/ipykernel_5720/1636029199.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"cleaned_comment\"] = df1.swifter.apply(lambda x: clean_text(x[\"comment\"]),axis=1)\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english')) - {'no','not','nor','against','above','below','off','own'}\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "def clean_text(comment):\n",
    "    text = str(comment)\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ',text)\n",
    "    text = re.sub(\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"[0-9]+\",\" \",text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\",\" \",text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"n\\'t\", ' not',text)\n",
    "    text = text.replace('\\\\r', ' ')\n",
    "    text = text.replace('\\\\\"', ' ')\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    text = re.sub('[^A-Za-z0-9]+',' ', text)\n",
    "    text = ' '.join(token for token in tokenizer.tokenize(text.lower()) if token not in stops)\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "df1[\"cleaned_comment\"] = df1.swifter.apply(lambda x: clean_text(x[\"comment\"]),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515596</th>\n",
       "      <td>would actually let tech less grave state depen...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839865</th>\n",
       "      <td>hope</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361527</th>\n",
       "      <td>ask supporting serious mind cruz equally conce...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783999</th>\n",
       "      <td>yahoo</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476848</th>\n",
       "      <td>brilliant observation</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cleaned_comment       label\n",
       "515596  would actually let tech less grave state depen...  __label__0\n",
       "839865                                               hope  __label__1\n",
       "361527  ask supporting serious mind cruz equally conce...  __label__0\n",
       "783999                                              yahoo  __label__1\n",
       "476848                              brilliant observation  __label__1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, val_x,train_y , val_y = train_test_split(df1.drop('label',axis=1),df['label'],random_state=123,test_size=0.20)\n",
    "train_txt = train_x['cleaned_comment']\n",
    "val_txt = val_x['cleaned_comment']\n",
    "train = pd.concat([train_x, train_y], axis=1)\n",
    "val = pd.concat([val_x, val_y], axis=1)\n",
    "train.drop(['comment'],axis=1,inplace=True)\n",
    "val.drop(['comment'],axis=1,inplace=True)\n",
    "train.iloc[:, 1] = train.iloc[:, 1].apply(lambda x: '__label__' + str(x))\n",
    "val.iloc[:, 1] = val.iloc[:, 1].apply(lambda x: '__label__' + str(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_train_path = r'C:\\Users\\prasr\\Documents\\Northeastern\\IDMP\\Project\\reddit_sarcasm_detection\\data\\interim\\fasttext_train.txt'\n",
    "fasttext_val_path = r'C:\\Users\\prasr\\Documents\\Northeastern\\IDMP\\Project\\reddit_sarcasm_detection\\data\\interim\\fasttext_val.txt'\n",
    "\n",
    "train[['label','cleaned_comment']].to_csv(fasttext_train_path, \n",
    "                                            index = False, sep = ' ',header = None, quoting = csv.QUOTE_NONE,\n",
    "                                            quotechar = \"\", escapechar = \" \")\n",
    "val[['label','cleaned_comment']].to_csv(fasttext_val_path, \n",
    "                                            index = False, sep = ' ',header = None, quoting = csv.QUOTE_NONE,\n",
    "                                            quotechar = \"\", escapechar = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(fasttext_train_path, wordNgrams = 2, epoch = 5, verbose = 1, loss = 'ova',lr=0.099, ws = 8, dim = 300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200935, 0.6866200512603579, 0.6866200512603579)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(fasttext_val_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36f0e4b0a7ea5d9009060c84ac0572df4a90298368e23ad6ca51e547eda0a6da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('NLP_sarcasm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
